{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701317560536,
     "user": {
      "displayName": "Luis Mario Nunez Beltran",
      "userId": "06293216306995136507"
     },
     "user_tz": 360
    },
    "id": "B6uxkeDhy8ww"
   },
   "outputs": [],
   "source": [
    "#The purpose of the preprocess_input function is to preprocess the input images before feeding them to an EfficientNet model\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "#This line imports the `EfficientNetB0` model from Keras' applications module\n",
    "from keras.applications import EfficientNetB0\n",
    "#This imports the `Sequential` model from Keras. A Sequential model is a stack of layers.\n",
    "#It's a basic form of neural network model in Keras where you can simply add layers to the model in sequence.\n",
    "#This is a \"linear\" arrangement in the sense that the data flows through the layers in a single path, without branching or merging.\n",
    "from keras.models import Sequential\n",
    "# - This line imports specific layers that you can add to your neural network:\n",
    "#     - `GlobalAveragePooling2D`: A layer that averages each feature map to a single number.\n",
    "#     - `Dropout`: This layer randomly sets a fraction of input units to 0 at each update during training\n",
    "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "#Keras might not have every possible metric or loss function you need and although the RMSE, for instance,\n",
    "#is a standard metric for regression problems, it is not directly available as a built-in function in Keras.\n",
    "#Keras does not provide \"low-level\" operations such as tensor multiplication and convolution.\n",
    "#Instead, it relies on the tensor library: `keras.backend` to handle these operations.\n",
    "#We are using that library to define our custom loss function.\n",
    "#By using `keras.backend`, your custom function remains compatible with whichever backend Keras is using.\n",
    "#This means you can write your code once and it will work whether you're using TensorFlow, Theano, or any other backend supported by Keras.\n",
    "# This allows for more flexible and portable code.\n",
    "import keras.backend as backend\n",
    "#ImageDataGenerator is a class in Keras used for real-time data augmentation.\n",
    "#'img_to_array' is a utility function that converts a loaded image (in the form of a PIL image or a similar object) into a NumPy array.\n",
    "#This conversion is necessary because deep learning models in Keras work with data in the form of NumPy arrays.\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "#The os module provides a way of using operating system-dependent functionality.\n",
    "#It allows you to interact with the operating system in various ways, such as navigating the file system, reading, and writing files,\n",
    "#querying and setting environment variables, and executing system commands.\n",
    "import os\n",
    "#cv2 provides tools that are essential for many tasks in the field of computer vision and image processing.\n",
    "import cv2\n",
    "#Import the ADAM optimizer\n",
    "from keras.optimizers import Adam\n",
    "#Remember that the Kaggle challenge includes a CSV file with the \"labels\" we are to predict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The probability distributions for the classifications for each of the training images comes in a CSV file.\n",
    "#The columns of the CSV file are: \"GalxaxyID, Class1.1, Class1.2, ...\"\n",
    "classes = [\n",
    "    'Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2', 'Class3.1',\n",
    "    'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2', 'Class5.3',\n",
    "    'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2', 'Class7.3',\n",
    "    'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6',\n",
    "    'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2',\n",
    "    'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4',\n",
    "    'Class11.5', 'Class11.6'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cropping we explained above\n",
    "def random_input(img):\n",
    "    #By using [:2], we ignore the number of channels and keep just the height and width.\n",
    "    shape = img.shape[:2]\n",
    "    #These lines calculate one-fourth of the height and width of the image, respectively.\n",
    "    left = int(shape[0]/4)\n",
    "    top = int(shape[1]/4)\n",
    "    #This line crops the image to a central region.\n",
    "    #It selects a square from the image that starts at (left, top) and extends to three times the value of left and top.\n",
    "    img = img[left:left*3,top:top*3,:]\n",
    "    #After cropping, the image is resized back to its original dimensions\n",
    "    #interpolation=cv2.INTER_CUBIC argument specifies the interpolation method to be cubic, which is a method that generally provides good results.\n",
    "    image = cv2.resize(img, shape, interpolation = cv2.INTER_CUBIC)\n",
    "    #This line converts the resized image into a NumPy array using the img_to_array function.\n",
    "    #This conversion is necessary because Keras models expect input in the form of NumPy arrays.\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    #Apply EfficientNetB0 preprocess_input\n",
    "    return preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we construct a neural network model using Keras utilizing the EfficientNetB0 architecture as the base model.\n",
    "def build_model():\n",
    "    #This line initializes an EfficientNetB0 model pre-trained on the ImageNet dataset.\n",
    "    #weights='imagenet' indicates that the model should be loaded with weights trained on the ImageNet dataset.\n",
    "    #include_top=False means that the top layer of the model (a fully connected layer for classification) is not included. This allows for custom layers to be added for specific tasks.\n",
    "    #input_shape=(224, 224, 3) sets the shape of the input images to 224x224 pixels with 3 color channels (RGB).\n",
    "    eff1 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    #This \"freezes\" these layers, meaning their weights will not be updated during training.\n",
    "    #This is a common practice when using a pre-trained model as a feature extractor,\n",
    "    #as it allows the model to maintain the knowledge it has gained from the original training dataset (ImageNet in this case).\n",
    "    #for layer in eff1.layers:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    #model = Sequential(): This line initializes a new Sequential model.\n",
    "    model = Sequential()\n",
    "    #model.add(eff1): Adds the EfficientNetB0 model as the base of the new model.\n",
    "    model.add(eff1)\n",
    "    #model.add(GlobalAveragePooling2D()): This layer applies global average pooling to the output of EfficientNetB0.\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    #model.add(Dropout(0.5)): This layer randomly sets input units to 0 with a frequency of 0.5 at each instance (image) during training.\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(64, activation='relu')): Adds a densely-connected Neural Network layer with 64 units and ReLU (Rectified Linear Unit) activation.\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dense(37, activation='sigmoid')): Finally, adds a Dense layer with 37 units and a sigmoid activation function.\n",
    "    model.add(Dense(37, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = build_model()  # Make sure you have a function that builds your model architecture\n",
    "model.load_weights('C:/Users/usuario/Desktop/DL_project_Jupyter/weights_efficientnetB0.hdf5')  # Path to your optimal weigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79975 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#This line sets the variable train_path to the path of a directory that contains the training images\n",
    "#train_path = \"/content/drive/Othercomputers/Mi portaÃÅtil/images_training_rev1\"\n",
    "test_path = 'C:/Users/usuario/Desktop/DL_project_Jupyter/images_test_rev1'\n",
    "\n",
    "# Prepare the test data\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=random_input)\n",
    "\n",
    "#Use 'None' because we don't have labels for the test set\n",
    "\n",
    "#The flow_from_directory method expects the directory to contain one subdirectory per class, \n",
    "#and each subdirectory should contain the images that belong to that class. \n",
    "#Since you're working with test images that don't have labels, \n",
    "#you need to ensure that all test images are in a single subdirectory within the test_path directory.\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=70,\n",
    "    class_mode=None,  \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143/1143 [==============================] - 9219s 8s/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "#Generating the predictions for the input samples from a data generator.\n",
    "#`model.predict(...)`: This tells Keras to make predictions on the input data provided.\n",
    "\n",
    "#`test_generator`: This is the data generator that we previously defined. \n",
    "#It yields batches of test data that the model will predict on.\n",
    "\n",
    "#`steps=np.ceil(test_generator.samples/test_generator.batch_size)`: \n",
    "#The `steps` argument specifies how many batches of samples to draw from the generator before declaring one epoch finished \n",
    "#and stopping prediction. Since the generator is producing batches of data, you need to tell the `predict` method \n",
    "#how many steps it should take to process the entire test set. \n",
    "#This is calculated by dividing the total number of samples (`test_generator.samples`) by \n",
    "#the batch size (`test_generator.batch_size`) to get the number of steps per epoch. \n",
    "#Since this can result in a float value, `np.ceil` is used to round up to the nearest whole number, \n",
    "#ensuring that you don't miss any samples.\n",
    "\n",
    "#`verbose=1`: When set to 1, it will show a progress bar during prediction, \n",
    "#which can be helpful to visualize the prediction process, especially if it takes a long time to run.\n",
    "\n",
    "test_predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples/test_generator.batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of file paths from the test generator\n",
    "file_paths = test_generator.filepaths\n",
    "\n",
    "#Extract GalaxyID from each file path\n",
    "#- `file_paths`: This variable is a list of strings, where each string is a full path to an image file.\n",
    "#- `os.path.basename(path)`: The `os.path.basename` function takes a file path and returns the base name of the file. \n",
    "#For example, if the path is `/kaggle/input/galaxy-zoo-the-galaxy-challenge/images_training_rev1/100008.jpg`, \n",
    "#`os.path.basename(path)` would return `100008.jpg`.\n",
    "#- `.split('.')[0]`: This part takes the base file name (e.g., `100008.jpg`) and splits it at the period character, \n",
    "#The `split` function returns a list, and `[0]` accesses the first element of this list. \n",
    "#In the case of `100008.jpg`, the `split('.')[0]` would result in `100008`\n",
    "galaxy_ids = [os.path.basename(path).split('.')[0] for path in file_paths]\n",
    "\n",
    "#Create a DataFrame with GalaxyID as the first column\n",
    "results_df = pd.DataFrame({'GalaxyID': galaxy_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A loop that iterates over the list of class names and assigns the corresponding predictions \n",
    "#to a new column in the `results_df` DataFrame for each class.\n",
    "\n",
    "#`enumerate(classes)`: The `enumerate` function is used to loop over something and have an automatic counter. \n",
    "#Here it's used on the list `classes`, which contains the class names as strings (like 'Class1.1', 'Class1.2', etc.). \n",
    "#The function provides two values on each iteration: `i` (the index or counter) and `class_name` (the value from the list).\n",
    "\n",
    "#`for i, class_name in enumerate(classes)`: \n",
    "#This sets up a loop that will go through the `classes` list, with `i` being the index (starting from 0) and \n",
    "#`class_name` being the string value of each class.\n",
    "for i, class_name in enumerate(classes):\n",
    "    #`results_df[class_name]` creates a new column in the `results_df` DataFrame with the name of \n",
    "    #the current class (e.g., 'Class1.1').\n",
    "    #`test_predictions[:, i]` selects all the predictions for that class from the `test_predictions` array. \n",
    "    #The `:` means \"select all rows\" in the array, and `i` is the index for the column corresponding to the current class.\n",
    "    results_df[class_name] = test_predictions[:, i]\n",
    "\n",
    "# Now results_df has GalaxyID and all the class columns with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DataFrame to a CSV file\n",
    "results_df.to_csv('C:/Users/usuario/Desktop/DL_project_Jupyter/galaxy_zoo_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701317560536,
     "user": {
      "displayName": "Luis Mario Nunez Beltran",
      "userId": "06293216306995136507"
     },
     "user_tz": 360
    },
    "id": "Yi_e6L_EPgg4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1701317561582,
     "user": {
      "displayName": "Luis Mario Nunez Beltran",
      "userId": "06293216306995136507"
     },
     "user_tz": 360
    },
    "id": "sGDsplyOaXaG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ_bj4stuALI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMsDRTBTnUl2D6t0irDovbd",
   "provenance": [
    {
     "file_id": "1cwMtXfV7ORmGALR1XFqXwkTXpzrMq1he",
     "timestamp": 1701206153140
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
